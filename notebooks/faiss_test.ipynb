{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import clip\n",
    "sys.path.append('../.')\n",
    "from Metrics import nmi, acc, base_kmeans_model_evaluation, kmeans_with_init\n",
    "from networks import CustomCLIP, load_clip_to_cpu\n",
    "from lr_scheduler import ConstantWarmupScheduler\n",
    "import faiss\n",
    "import argparse\n",
    "batch_size = 50\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "backbone_name = \"ViT-L/14\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = load_clip_to_cpu(backbone_name)\n",
    "clip_model.to(device)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=preprocess) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                        download=True, transform=preprocess)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "concatset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "concatloader = torch.utils.data.DataLoader(concatset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(testset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def faiss_kmeans_model_evaluation(model, data_loader, num_cluster):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        dataset_size = len(data_loader.dataset)\n",
    "        datas = np.zeros([dataset_size, 768])\n",
    "        label_true = np.zeros(dataset_size)\n",
    "        ii = 0\n",
    "        for x, target in data_loader:\n",
    "            b = x.shape[0]\n",
    "            x = Variable(x).cuda()\n",
    "            image_representation = model.encode_image(x)\n",
    "            image_representation = image_representation / \\\n",
    "                image_representation.norm(dim=-1, keepdim=True)\n",
    "            u = image_representation.cpu()\n",
    "            datas[ii * data_loader.batch_size:(ii + 1) *\n",
    "                  data_loader.batch_size, :] = u.data.numpy()\n",
    "            label_true[ii * data_loader.batch_size:(ii + 1)\n",
    "                       * data_loader.batch_size] = target.numpy()\n",
    "            ii = ii + 1\n",
    "        print(time.time()-start)\n",
    "#         kmeans = KMeans(n_clusters=num_cluster, random_state=0).fit(datas)\n",
    "        return datas, label_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    datas,label_true = faiss_kmeans_model_evaluation(\n",
    "        clip_model, trainloader, num_classes)\n",
    "# np.save('../npy_folder/test_cluster.npy', test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = faiss.Kmeans(d=datas.shape[-1], k=num_classes, niter=10, verbose=True,gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a subset of 2560 / 50000 for training\n",
      "Clustering 2560 points in 768D to 10 clusters, redo 1 times, 10 iterations\n",
      "  Preprocessing in 0.02 s\n",
      "  Iteration 0 (0.00 s, search 0.00 s): objective=779.426 imbalance=1.618 nsplit=0       \r",
      "  Iteration 1 (0.00 s, search 0.00 s): objective=465.254 imbalance=1.220 nsplit=0       \r",
      "  Iteration 2 (0.00 s, search 0.00 s): objective=451.802 imbalance=1.167 nsplit=0       \r",
      "  Iteration 3 (0.01 s, search 0.00 s): objective=450.003 imbalance=1.158 nsplit=0       \r",
      "  Iteration 4 (0.01 s, search 0.00 s): objective=448.796 imbalance=1.154 nsplit=0       \r",
      "  Iteration 5 (0.01 s, search 0.01 s): objective=447.758 imbalance=1.157 nsplit=0       \r",
      "  Iteration 6 (0.01 s, search 0.01 s): objective=447.386 imbalance=1.160 nsplit=0       \r",
      "  Iteration 7 (0.01 s, search 0.01 s): objective=447.274 imbalance=1.162 nsplit=0       \r",
      "  Iteration 8 (0.01 s, search 0.01 s): objective=447.257 imbalance=1.162 nsplit=0       \r",
      "  Iteration 9 (0.01 s, search 0.01 s): objective=447.246 imbalance=1.162 nsplit=0       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "447.2464599609375"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datas = datas.astype(np.float32)\n",
    "kmeans.train(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = datas.astype(np.float32)\n",
    "dists, label_pred = kmeans.index.search(datas, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(label_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = acc(label_true, label_pred, 10)\n",
    "NMI = nmi(label_true, label_pred.squeeze(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82898 0.8682115603685252\n"
     ]
    }
   ],
   "source": [
    "print(ACC,NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_ACC 0.95328\n",
      "image_NMI 0.9012859197933579\n"
     ]
    }
   ],
   "source": [
    "# kmeans = KMeans(n_clusters=10, random_state=0).fit(datas)\n",
    "# label_pred = kmeans.labels_\n",
    "# centroids = kmeans.cluster_centers_\n",
    "ACC = acc(label_true, label_pred, 10)\n",
    "NMI = nmi(label_true, label_pred)\n",
    "print('image_ACC', ACC)\n",
    "print('image_NMI', NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
