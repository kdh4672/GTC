{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acdb4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14']\n",
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 4\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "dataset_length: 10000\n",
      "Initializing class-specific contexts\n",
      "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 16\n",
      "done\n",
      "==================================================================\n",
      "dpoch: 0\n",
      "train_iter: 49 / 200\n",
      "target: tensor(0, device='cuda:0')\n",
      "output: tensor([21.1642, 14.1570, 13.0157, 16.7233, 17.4331, 14.9311, 16.4505, 11.4311,\n",
      "        11.9358, 15.0253], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([9.5220e-01, 8.6212e-04, 2.7536e-04, 1.1222e-02, 2.2823e-02, 1.8697e-03,\n",
      "        8.5427e-03, 5.6456e-05, 9.3520e-05, 2.0542e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.8673, device='cuda:0')\n",
      "train_iter: 99 / 200\n",
      "target: tensor(7, device='cuda:0')\n",
      "output: tensor([12.5856, 11.9228, 14.0092, 10.4251, 13.9665, 13.8861, 10.8423, 23.3324,\n",
      "        16.5119, 11.7839], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([2.1485e-05, 1.1074e-05, 8.9209e-05, 2.4765e-06, 8.5477e-05, 7.8871e-05,\n",
      "        3.7586e-06, 9.9861e-01, 1.0897e-03, 9.6375e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9113, device='cuda:0')\n",
      "train_iter: 149 / 200\n",
      "target: tensor(0, device='cuda:0')\n",
      "output: tensor([19.3482, 13.2668, 10.1403, 11.8857, 13.4852, 14.9401, 14.4904, 14.1900,\n",
      "        10.1193, 12.6482], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([9.6821e-01, 2.2125e-03, 9.7059e-05, 5.5598e-04, 2.7524e-03, 1.1792e-02,\n",
      "        7.5210e-03, 5.5692e-03, 9.5048e-05, 1.1919e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9281, device='cuda:0')\n",
      "train_iter: 199 / 200\n",
      "target: tensor(0, device='cuda:0')\n",
      "output: tensor([23.7781, 12.1786,  8.9927, 13.4119, 10.9494, 10.8991, 12.9006, 10.4312,\n",
      "        10.8969, 12.2368], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([9.9992e-01, 9.1698e-06, 3.7908e-07, 3.1477e-05, 2.6824e-06, 2.5509e-06,\n",
      "        1.8877e-05, 1.5977e-06, 2.5452e-06, 9.7196e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9377, device='cuda:0')\n",
      "train_accuracy:  tensor(0.9330, device='cuda:0')\n",
      "==================================================================\n",
      "dpoch: 1\n",
      "train_iter: 49 / 200\n",
      "target: tensor(6, device='cuda:0')\n",
      "output: tensor([14.8629,  6.1143,  4.3751, 10.6833, 10.7311,  9.5849, 24.5460,  7.3526,\n",
      "         5.4569, 10.5391], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([6.2324e-05, 9.8901e-09, 1.7372e-09, 9.5382e-07, 1.0005e-06, 3.1803e-07,\n",
      "        9.9993e-01, 3.4116e-08, 5.1249e-09, 8.2579e-07], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(1., device='cuda:0')\n",
      "train_iter: 99 / 200\n",
      "target: tensor(4, device='cuda:0')\n",
      "output: tensor([10.9014, 11.6897, 13.1177, 11.6538, 20.9634, 12.0625, 10.4736, 11.5394,\n",
      "        13.1344, 12.0730], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([4.2610e-05, 9.3725e-05, 3.9088e-04, 9.0424e-05, 9.9860e-01, 1.3608e-04,\n",
      "        2.7780e-05, 8.0645e-05, 3.9745e-04, 1.3751e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9848, device='cuda:0')\n",
      "train_iter: 149 / 200\n",
      "target: tensor(0, device='cuda:0')\n",
      "output: tensor([23.2463, 13.2995, 14.3189, 11.9767, 13.0493, 13.8890, 13.4153, 12.3547,\n",
      "        11.8976, 12.4190], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([9.9958e-01, 4.7859e-05, 1.3265e-04, 1.2750e-05, 3.7266e-05, 8.6291e-05,\n",
      "        5.3737e-05, 1.8606e-05, 1.1780e-05, 1.9842e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9776, device='cuda:0')\n",
      "train_iter: 199 / 200\n",
      "target: tensor(0, device='cuda:0')\n",
      "output: tensor([23.6284, 12.2677, 14.1731,  8.3454, 13.8665, 12.0847, 11.0425, 11.8914,\n",
      "         9.5029, 11.8169], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([9.9982e-01, 1.1642e-05, 7.8261e-05, 2.3046e-07, 5.7594e-05, 9.6952e-06,\n",
      "        3.4192e-06, 7.9914e-06, 7.3334e-07, 7.4175e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9763, device='cuda:0')\n",
      "train_accuracy:  tensor(0.9714, device='cuda:0')\n",
      "==================================================================\n",
      "dpoch: 2\n",
      "train_iter: 49 / 200\n",
      "target: tensor(0, device='cuda:0')\n",
      "output: tensor([23.1052, 14.6452, 11.7634,  7.6428, 12.5825,  9.8823, 12.6950,  7.3957,\n",
      "         9.3894,  8.5416], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([9.9972e-01, 2.1171e-04, 1.1863e-05, 1.9258e-07, 2.6910e-05, 1.8081e-06,\n",
      "        3.0114e-05, 1.5043e-07, 1.1045e-06, 4.7311e-07], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(1.0029, device='cuda:0')\n",
      "train_iter: 99 / 200\n",
      "target: tensor(4, device='cuda:0')\n",
      "output: tensor([ 2.8274,  5.6881,  5.3878,  4.0584, 20.1781,  6.5241,  4.5089,  6.6800,\n",
      "         8.3312,  7.6582], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([2.9154e-08, 5.0941e-07, 3.7728e-07, 9.9845e-08, 9.9999e-01, 1.1753e-06,\n",
      "        1.5666e-07, 1.3736e-06, 7.1609e-06, 3.6532e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9895, device='cuda:0')\n",
      "train_iter: 149 / 200\n",
      "target: tensor(3, device='cuda:0')\n",
      "output: tensor([11.0862,  8.7647,  6.0815, 22.8868,  6.5773, 17.8467,  9.7898,  8.9984,\n",
      "         9.8081,  9.7555], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([7.4518e-06, 7.3121e-07, 4.9973e-08, 9.9355e-01, 8.2050e-08, 6.4318e-03,\n",
      "        2.0383e-06, 9.2373e-07, 2.0758e-06, 1.9694e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9875, device='cuda:0')\n",
      "train_iter: 199 / 200\n",
      "target: tensor(9, device='cuda:0')\n",
      "output: tensor([ 7.9619,  6.3383, 10.6681,  7.0384, 10.5655, 15.7171,  9.2224,  6.3440,\n",
      "        13.2936, 25.2489], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([3.1069e-08, 6.1262e-09, 4.6516e-07, 1.2337e-08, 4.1982e-07, 7.2502e-05,\n",
      "        1.0958e-07, 6.1611e-09, 6.4245e-06, 9.9992e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9855, device='cuda:0')\n",
      "train_accuracy:  tensor(0.9806, device='cuda:0')\n",
      "==================================================================\n",
      "dpoch: 3\n",
      "train_iter: 49 / 200\n",
      "target: tensor(3, device='cuda:0')\n",
      "output: tensor([-2.1148,  1.6539, -2.1511, 18.2519,  2.4398, 18.3250, -0.0701,  5.0920,\n",
      "         4.5991,  5.1222], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([6.8810e-10, 2.9813e-08, 6.6359e-10, 4.8176e-01, 6.5418e-08, 5.1824e-01,\n",
      "        5.3170e-09, 9.2799e-07, 5.6684e-07, 9.5640e-07], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(1.0024, device='cuda:0')\n",
      "train_iter: 99 / 200\n",
      "target: tensor(2, device='cuda:0')\n",
      "output: tensor([ 6.4034,  5.4907, 18.6466,  5.9129,  8.6530,  7.3965,  4.8103,  9.4745,\n",
      "         6.2238,  5.8689], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([4.8170e-06, 1.9338e-06, 9.9982e-01, 2.9495e-06, 4.5683e-05, 1.3004e-05,\n",
      "        9.7930e-07, 1.0388e-04, 4.0249e-06, 2.8227e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9937, device='cuda:0')\n",
      "train_iter: 149 / 200\n",
      "target: tensor(4, device='cuda:0')\n",
      "output: tensor([ 9.1492,  4.6341,  8.5258,  3.1857, 21.7946,  4.9959,  7.6223,  9.0479,\n",
      "         7.4780,  8.1337], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([3.2225e-06, 3.5262e-08, 1.7276e-06, 8.2848e-09, 9.9999e-01, 5.0634e-08,\n",
      "        6.9990e-07, 2.9118e-06, 6.0587e-07, 1.1672e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9898, device='cuda:0')\n",
      "train_iter: 199 / 200\n",
      "target: tensor(2, device='cuda:0')\n",
      "output: tensor([12.0475, 11.1110, 24.0731,  9.5989, 12.1030,  7.3928,  8.5264,  9.2466,\n",
      "        11.8947,  8.8045], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([5.9890e-06, 2.3476e-06, 9.9998e-01, 5.1749e-07, 6.3303e-06, 5.6992e-08,\n",
      "        1.7707e-07, 3.6386e-07, 5.1400e-06, 2.3383e-07], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9869, device='cuda:0')\n",
      "train_accuracy:  tensor(0.9820, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_ACC 0.8341\n",
      "image_NMI 0.8421861881355762\n",
      "val_acc 0.8341\n",
      "val_nmi 0.8421861881355762\n",
      "Initializing class-specific contexts\n",
      "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 16\n",
      "==================================================================\n",
      "dpoch: 4\n",
      "train_iter: 49 / 200\n",
      "target: tensor(2, device='cuda:0')\n",
      "output: tensor([12.4759, 12.8622, 22.1983, 13.0940, 13.0762, 12.7444,  8.5321, 14.3705,\n",
      "        12.7757, 13.5017], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([5.9857e-05, 8.8088e-05, 9.9891e-01, 1.1106e-04, 1.0910e-04, 7.8292e-05,\n",
      "        1.1597e-06, 3.9805e-04, 8.0785e-05, 1.6697e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9073, device='cuda:0')\n",
      "train_iter: 99 / 200\n",
      "target: tensor(6, device='cuda:0')\n",
      "output: tensor([14.8613, 11.7474, 11.1213, 14.4216, 11.8092, 13.4982, 24.5102, 10.4790,\n",
      "        10.0835, 13.8202], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([6.4490e-05, 2.8651e-06, 1.5319e-06, 4.1545e-05, 3.0476e-06, 1.6501e-05,\n",
      "        9.9985e-01, 8.0589e-07, 5.4266e-07, 2.2770e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9299, device='cuda:0')\n",
      "train_iter: 149 / 200\n",
      "target: tensor(8, device='cuda:0')\n",
      "output: tensor([16.2505, 11.8161, 13.8661, 11.1541, 15.1215, 15.5913, 13.5148, 12.6863,\n",
      "        20.7598, 12.8390], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([1.0761e-02, 1.2764e-04, 9.9148e-04, 6.5840e-05, 3.4794e-03, 5.5659e-03,\n",
      "        6.9778e-04, 3.0475e-04, 9.7765e-01, 3.5499e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9411, device='cuda:0')\n",
      "train_iter: 199 / 200\n",
      "target: tensor(6, device='cuda:0')\n",
      "output: tensor([20.1803,  6.5683,  8.4444, 15.3023, 13.0329,  9.9357, 20.6900, 10.8097,\n",
      "        10.1866, 10.0442], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([3.7405e-01, 4.5849e-07, 2.9928e-06, 2.8475e-03, 2.9434e-04, 1.3297e-05,\n",
      "        6.2273e-01, 3.1867e-05, 1.7089e-05, 1.4821e-05], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9476, device='cuda:0')\n",
      "train_accuracy:  tensor(0.9429, device='cuda:0')\n",
      "==================================================================\n",
      "dpoch: 5\n",
      "train_iter: 49 / 200\n",
      "target: tensor(6, device='cuda:0')\n",
      "output: tensor([12.8033,  8.9445, 11.2857, 11.0116, 12.8854, 14.8747, 22.3096, 11.9910,\n",
      "        10.2139, 14.3396], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([7.4297e-05, 1.5672e-06, 1.6289e-05, 1.2384e-05, 8.0656e-05, 5.8959e-04,\n",
      "        9.9884e-01, 3.2974e-05, 5.5770e-06, 3.4527e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9959, device='cuda:0')\n",
      "train_iter: 99 / 200\n",
      "target: tensor(1, device='cuda:0')\n",
      "output: tensor([13.1324, 22.9691, 12.6777, 14.0069, 13.3594, 14.7424, 11.3054, 13.2356,\n",
      "        12.2125,  8.9253], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "softmax_output: tensor([5.3420e-05, 9.9936e-01, 3.3903e-05, 1.2809e-04, 6.7035e-05, 2.6726e-04,\n",
      "        8.5956e-06, 5.9231e-05, 2.1292e-05, 7.9539e-07], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "accuracy: tensor(0.9838, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 157>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    165\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 166\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, targets)\n\u001b[1;32m    168\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/kcc/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/clustering/tgc_v1/notebooks/../networks.py:119\u001b[0m, in \u001b[0;36mCustomCLIP.forward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    117\u001b[0m prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_learner()\n\u001b[1;32m    118\u001b[0m tokenized_prompts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenized_prompts\n\u001b[0;32m--> 119\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_prompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m image_features \u001b[38;5;241m=\u001b[39m image_features \u001b[38;5;241m/\u001b[39m \\\n\u001b[1;32m    122\u001b[0m     image_features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m text_features \u001b[38;5;241m=\u001b[39m text_features \u001b[38;5;241m/\u001b[39m \\\n\u001b[1;32m    124\u001b[0m     text_features\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/kcc/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/clustering/tgc_v1/notebooks/../networks.py:39\u001b[0m, in \u001b[0;36mTextEncoder.forward\u001b[0;34m(self, prompts, tokenized_prompts)\u001b[0m\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_final(x)\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# x.shape = [batch_size, n_ctx, transformer.width]\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# take features from the eot embedding (eot_token is the highest number in each sequence)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenized_prompts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_projection\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from operator import is_\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import clip\n",
    "sys.path.append(\"../\")\n",
    "from Metrics import base_kmeans_model_evaluation, kmeans_with_init, cosine_kmeans_with_init\n",
    "from networks import CustomCLIP, load_clip_to_cpu\n",
    "from lr_scheduler import ConstantWarmupScheduler\n",
    "\n",
    "import argparse\n",
    "\n",
    "# parser\n",
    "clip_backbone=\"ViT-L/14\"\n",
    "batch_size=50\n",
    "total_epoch=5\n",
    "lr=3e-4\n",
    "scheduler_operate=False\n",
    "repeat=4\n",
    "is_test_dataset = False\n",
    "cosine_sim=True\n",
    "n_ctx=16\n",
    "total_dpoch = repeat\n",
    "# parser\n",
    "\n",
    "print(clip.available_models())\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else \"cpu\"\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "\n",
    "backbone_name = clip_backbone\n",
    "clip_model, preprocess = load_clip_to_cpu(backbone_name)\n",
    "\n",
    "\n",
    "if is_test_dataset:\n",
    "    fixed_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                                 download=True, transform=preprocess)\n",
    "    fixed_testloader = torch.utils.data.DataLoader(fixed_testset, batch_size=batch_size,\n",
    "                                                   shuffle=False)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=preprocess)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False)\n",
    "else:\n",
    "    fixed_cset1 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                               download=True, transform=preprocess)\n",
    "    fixed_cset2 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                               download=True, transform=preprocess)\n",
    "    fixed_testset = torch.utils.data.ConcatDataset([fixed_cset1, fixed_cset2])\n",
    "\n",
    "    fixed_testloader = torch.utils.data.DataLoader(fixed_testset, batch_size=batch_size,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "    cset1 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                         download=True, transform=preprocess)\n",
    "    cset2 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                         download=True, transform=preprocess)\n",
    "    testset = torch.utils.data.ConcatDataset([cset1, cset2])\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=False)\n",
    "\n",
    "print(\"dataset_length:\", len(testset))\n",
    "if is_test_dataset:\n",
    "    num_classes = len(fixed_testloader.dataset.classes)\n",
    "else:\n",
    "    num_classes = len(cset1.classes)\n",
    "model = CustomCLIP(clip_model, num_classes, n_ctx=n_ctx)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"prompt_learner\" not in name:\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# device_count = torch.cuda.device_count()\n",
    "# if device_count > 1:\n",
    "#     print(\n",
    "#         f\"Multiple GPUs detected (n_gpus={device_count}), use all of them!\")\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "print('done')\n",
    "\n",
    "criterion = F.cross_entropy\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=lr,\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=5e-4,\n",
    "#     dampening=0,\n",
    "#     nesterov=False,\n",
    "# )\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    weight_decay=5e-4,\n",
    "    betas=(0.9, 0.999),\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, float(10)\n",
    ")\n",
    "scheduler = ConstantWarmupScheduler(\n",
    "    optimizer, lr_scheduler, 1,\n",
    "    1e-5\n",
    ")\n",
    "if not scheduler_operate:\n",
    "    scheduler = ConstantWarmupScheduler(\n",
    "        optimizer, lr_scheduler, 1,\n",
    "        lr\n",
    "    )\n",
    "# initialization\n",
    "# clip_model.to(device)\n",
    "# with torch.no_grad():\n",
    "#     first_centroids, label, acc = base_kmeans_model_evaluation(\n",
    "#         clip_model, shortloader, num_classes)\n",
    "\n",
    "# testloader label update with k-mean clsuter result\n",
    "\n",
    "# shortset.targets = label\n",
    "# trainloader = torch.utils.data.DataLoader(shortset, batch_size=batch_size,\n",
    "#                                           shuffle=True)\n",
    "\n",
    "train_cluster = np.load('../npy_folder/train_cluster.npy')\n",
    "test_cluster = np.load('../npy_folder/test_cluster.npy')\n",
    "concat_cluster = np.load('../npy_folder/concat_cluster.npy')\n",
    "if is_test_dataset:\n",
    "    testset.targets = test_cluster.tolist()\n",
    "else:\n",
    "    cset1.targets = concat_cluster[:len(cset1)].tolist()\n",
    "    cset2.targets = concat_cluster[len(cset1):].tolist()\n",
    "    testset = torch.utils.data.ConcatDataset([cset1, cset2])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# real_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "#                                             download=True, transform=preprocess)\n",
    "\n",
    "# testloader = torch.utils.data.DataLoader(\n",
    "#     real_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "total_epoch = 200\n",
    "sm = nn.Softmax(dim=1)\n",
    "for epoch in range(total_epoch):\n",
    "    for dpoch in range(total_dpoch):\n",
    "        score = 0\n",
    "        total_loss = 0\n",
    "        print('==================================================================')\n",
    "        print('dpoch:', dpoch + total_dpoch * epoch)\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            score += torch.sum(pred == targets)\n",
    "            total_loss += loss.item()\n",
    "            if i % 50 == 49:\n",
    "                print('train_iter:', i, '/', len(testloader))\n",
    "                print('target:',targets[0])\n",
    "                print(\"output:\",output[0])\n",
    "                print(\"softmax_output:\",sm(output)[0])\n",
    "                print(\"accuracy:\",score/(i*batch_size))\n",
    "        print(\"train_accuracy: \", score/len(testloader.dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        prompts = model.prompt_learner()\n",
    "        tokenized_prompts = model.tokenized_prompts\n",
    "        text_centroids = model.text_encoder(\n",
    "            prompts, tokenized_prompts)\n",
    "        # no normalized\n",
    "        if cosine_sim:\n",
    "            knn = cosine_kmeans_with_init\n",
    "        else:\n",
    "            knn = kmeans_with_init\n",
    "        new_label, acc, nmi = knn(\n",
    "            model, fixed_testloader, num_classes, text_centroids)\n",
    "        print(\"val_acc\", acc)\n",
    "        print(\"val_nmi\", nmi)\n",
    "\n",
    "        model.train()\n",
    "# new cluster assignments\n",
    "    if is_test_dataset:\n",
    "        testset.targets = new_label.tolist()\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            testset, batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        cset1.targets = new_label[:len(cset1)].tolist()\n",
    "        cset2.targets = new_label[len(cset1):].tolist()\n",
    "        testset = torch.utils.data.ConcatDataset([cset1, cset2])\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "            testset, batch_size=batch_size, shuffle=True)\n",
    "# model reinitialization\n",
    "    model = CustomCLIP(clip_model, num_classes, n_ctx=n_ctx)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"prompt_learner\" not in name:\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # optimizer = torch.optim.SGD(\n",
    "    #     model.parameters(),\n",
    "    #     lr=lr,\n",
    "    #     momentum=0.9,\n",
    "    #     weight_decay=5e-4,\n",
    "    #     dampening=0,\n",
    "    #     nesterov=False,\n",
    "    # )\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=5e-4,\n",
    "        betas=(0.9, 0.999),\n",
    "    )\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, float(10)\n",
    "    )\n",
    "    scheduler = ConstantWarmupScheduler(\n",
    "        optimizer, lr_scheduler, 1,\n",
    "        1e-5\n",
    "    )\n",
    "    if not scheduler_operate:\n",
    "        scheduler = ConstantWarmupScheduler(\n",
    "            optimizer, lr_scheduler, 1,\n",
    "            lr\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab2a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/kkb/.local/share/jupyter/runtime/kernel-4abe0b4b-afd5-4470-afd4-4a3de269a396.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.lr = 0.1\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a57550",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43margs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ca68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([9.9989e-01, 2.5081e-05, 6.0233e-07, 7.8063e-07, 5.0855e-05, 5.3249e-06,\n",
    "        2.3968e-06, 1.6679e-06, 3.4923e-07, 2.1723e-05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d96831a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.999e-01, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e-04, 0.000e+00,\n",
       "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.round(x,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db00e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
