{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5918b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import clip\n",
    "sys.path.append('../.')\n",
    "from Metrics import nmi, acc, base_kmeans_model_evaluation, kmeans_with_init\n",
    "from networks import CustomCLIP, load_clip_to_cpu\n",
    "from lr_scheduler import ConstantWarmupScheduler\n",
    "import faiss\n",
    "import argparse\n",
    "batch_size = 50\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd5a90a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "backbone_name = \"ViT-L/14\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, preprocess = load_clip_to_cpu(backbone_name)\n",
    "clip_model.to(device)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ad2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True,\n",
    "                                        download=True, transform=preprocess) \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                        download=True, transform=preprocess)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "concatset = torch.utils.data.ConcatDataset([trainset, testset])\n",
    "concatloader = torch.utils.data.DataLoader(concatset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18ceb124",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(testset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e0d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def faiss_kmeans_model_evaluation(model, data_loader, num_cluster):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        dataset_size = len(data_loader.dataset)\n",
    "        datas = np.zeros([dataset_size, 768])\n",
    "        label_true = np.zeros(dataset_size)\n",
    "        ii = 0\n",
    "        for x, target in data_loader:\n",
    "            b = x.shape[0]\n",
    "            x = Variable(x).cuda()\n",
    "            image_representation = model.encode_image(x)\n",
    "            image_representation = image_representation / \\\n",
    "                image_representation.norm(dim=-1, keepdim=True)\n",
    "            u = image_representation.cpu()\n",
    "            datas[ii * data_loader.batch_size:(ii + 1) *\n",
    "                  data_loader.batch_size, :] = u.data.numpy()\n",
    "            label_true[ii * data_loader.batch_size:(ii + 1)\n",
    "                       * data_loader.batch_size] = target.numpy()\n",
    "            ii = ii + 1\n",
    "        print(time.time()-start)\n",
    "        start = time.time()\n",
    "#         kmeans = KMeans(n_clusters=num_cluster, random_state=0).fit(datas)\n",
    "        kmeans = faiss.Kmeans(d=datas.shape[-1],k=num_cluster, niter=10,gpu=True).fit(datas)        \n",
    "        print(time.time()-start)\n",
    "        label_pred = kmeans.labels_\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        ACC = acc(label_true, label_pred, num_cluster)\n",
    "        NMI = nmi(label_true, label_pred)\n",
    "        print('image_ACC', ACC)\n",
    "        print('image_NMI', NMI)\n",
    "        return centroids, label_pred, ACC, NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2629340",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ClusteringParameters' object has no attribute 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     second_centroids, test_label, acc, nmi\u001b[38;5;241m=\u001b[39m \u001b[43mfaiss_kmeans_model_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mfaiss_kmeans_model_evaluation\u001b[0;34m(model, data_loader, num_cluster)\u001b[0m\n\u001b[1;32m     21\u001b[0m         start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#         kmeans = KMeans(n_clusters=num_cluster, random_state=0).fit(datas)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m         kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(datas)        \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart)\n\u001b[1;32m     25\u001b[0m         label_pred \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/miniconda3/envs/kcc/lib/python3.8/site-packages/faiss/__init__.py:1514\u001b[0m, in \u001b[0;36mKmeans.__init__\u001b[0;34m(self, d, k, **kwargs)\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;66;03m# if this raises an exception, it means that it is a non-existent field\u001b[39;00m\n\u001b[0;32m-> 1514\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcp, k, v)\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ClusteringParameters' object has no attribute 'random_state'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    second_centroids, test_label, acc, nmi= faiss_kmeans_model_evaluation(\n",
    "        clip_model, testloader, num_classes)\n",
    "# np.save('../npy_folder/test_cluster.npy', test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11671565",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 128\n",
    "N = 10000\n",
    "K = 10  # The number of clusters\n",
    "X = np.random.random((N, D)).astype(np.float32)\n",
    "kmeans = faiss.Kmeans(d=D, k=K, niter=20, verbose=True,gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1374635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a subset of 2560 / 10000 for training\n",
      "Clustering 2560 points in 128D to 10 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 0 (0.02 s, search 0.00 s): objective=46221 imbalance=1.482 nsplit=0       \r",
      "  Iteration 1 (0.02 s, search 0.00 s): objective=26621.3 imbalance=1.229 nsplit=0       \r",
      "  Iteration 2 (0.02 s, search 0.00 s): objective=26528.6 imbalance=1.152 nsplit=0       \r",
      "  Iteration 3 (0.02 s, search 0.00 s): objective=26475.8 imbalance=1.107 nsplit=0       \r",
      "  Iteration 4 (0.02 s, search 0.00 s): objective=26443 imbalance=1.083 nsplit=0       \r",
      "  Iteration 5 (0.02 s, search 0.00 s): objective=26424.9 imbalance=1.072 nsplit=0       \r",
      "  Iteration 6 (0.02 s, search 0.00 s): objective=26413.6 imbalance=1.060 nsplit=0       \r",
      "  Iteration 7 (0.02 s, search 0.00 s): objective=26403.5 imbalance=1.055 nsplit=0       \r",
      "  Iteration 8 (0.02 s, search 0.00 s): objective=26395.4 imbalance=1.050 nsplit=0       \r",
      "  Iteration 9 (0.02 s, search 0.00 s): objective=26389.2 imbalance=1.047 nsplit=0       \r",
      "  Iteration 10 (0.02 s, search 0.00 s): objective=26385.2 imbalance=1.046 nsplit=0       \r",
      "  Iteration 11 (0.02 s, search 0.00 s): objective=26382.7 imbalance=1.046 nsplit=0       \r",
      "  Iteration 12 (0.02 s, search 0.01 s): objective=26381 imbalance=1.045 nsplit=0       \r",
      "  Iteration 13 (0.02 s, search 0.01 s): objective=26379.3 imbalance=1.043 nsplit=0       \r",
      "  Iteration 14 (0.03 s, search 0.01 s): objective=26377.7 imbalance=1.042 nsplit=0       \r",
      "  Iteration 15 (0.03 s, search 0.01 s): objective=26376 imbalance=1.041 nsplit=0       \r",
      "  Iteration 16 (0.03 s, search 0.01 s): objective=26373.7 imbalance=1.041 nsplit=0       \r",
      "  Iteration 17 (0.03 s, search 0.01 s): objective=26371.5 imbalance=1.039 nsplit=0       \r",
      "  Iteration 18 (0.03 s, search 0.01 s): objective=26369.8 imbalance=1.039 nsplit=0       \r",
      "  Iteration 19 (0.03 s, search 0.01 s): objective=26368.1 imbalance=1.038 nsplit=0       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26368.146484375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans.train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f400ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
